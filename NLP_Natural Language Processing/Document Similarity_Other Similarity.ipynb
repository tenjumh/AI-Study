{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 유클리드 거리(Euclidean distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유클리드 거리(euclidean distance)는 자카드 및 코사인 유사도 만큼 유용하지 않지만 개념을 이해하면 도움이 됨\n",
    "\n",
    "Euclidean Distance란, 다차원 공간에서 두개의 점p와 q가 각각 p=(p1, p2, p3, ..., pn)과 q=(q1, q2, q3, ..., qn)의 좌표를 가질 때 두 점 사이의 거리를 계산\n",
    "- 유클리드거리 공식\n",
    "![유클리드거리](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/Euclidean%20distance.PNG?raw=True)\n",
    "\n",
    "다차원 공간을 좀 더 쉽게 이해하기 위해 2차원 공간이라고 가정하고 두 점 사이의 거리를 좌표 평면 상에서 시각화 해보면    \n",
    "![유클리드 2차원 평면](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/%EC%9C%A0%ED%81%B4%EB%A6%AC%EB%93%9C%EA%B1%B0%EB%A6%AC_2%EC%B0%A8%EC%9B%90_%ED%8F%89%EB%A9%B4.png?raw=True)\n",
    "두 점 p와 q사이의 직선 거리를 구하는 문제로 피타고라스 정리를 통해 p와 q사이의 거리를 계산할 수 있다.\n",
    "<br>\n",
    "\n",
    "여러 문서에 대한 유사도를 구하고자 유클리드 거리 공식을 사용한다면 단어의 총 개수 만큼 차원을 확장한다.<br>\n",
    "아래와 같은 DTM이 있다고 한다면,\n",
    "![DTM표](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/DTM%20%ED%91%9C.PNG?raw=True)\n",
    "단어의 개수가 4개이므로 4차원 공간에 문서1, 문서2, 문서3을 배치하고 하기와 같은 문서Q에 대해서 문서1~문서3 중 가장 유사한 문서를 찾아내고자 한다.\n",
    "![DTM표2](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/DTM%20%ED%91%9C2.PNG?raw=True)\n",
    "유클리드 거리를 통해 유사도를 구하려고 한다면, 문서Q 또한 다른 문서들처럼 4차원 공간에 배치시크는 관점에서 4차원 공간에서의 각각의 문서들과의 유클리드 거리를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dist(x, y):\n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "doc1 = np.array((2,3,0,1))\n",
    "doc2 = np.array((1,2,3,1))\n",
    "doc3 = np.array((2,1,2,2))\n",
    "docQ = np.array((1,1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n",
      "3.1622776601683795\n",
      "2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "print(dist(doc1, docQ))\n",
    "print(dist(doc2, docQ))\n",
    "print(dist(doc3, docQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유클리드 거리의 값이 작은 것이 문서 간의 거리가 가장 가깝다는 것을 의미. 따라서 doc1과 docQ와 가장 유사하다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 자카드 유사도(Jaccard similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자카드 유사도란, A와 B 두 개의 집합이 있을 때, 합집합에서 교집합의 비율을 구한다면 두 집합 A와 B의 유사도를 구할수 있다.\n",
    " 자카드 유사도는 0과 1사이의 값을 가지며 만약 두 집합이 동일하다면 1의 값을 공통 원소가 없다면 0의 값을 갖는다. 자카드 유사도를 구하는 함수 J라고 하면 자카드 유사도 함수 J는 다음과 같다.\n",
    "![자카드 유사도](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/Jaccard%20similarity.PNG?raw=True)\n",
    "\n",
    "두 개의 비교할 문서를 각각 doc1, doc2라고 할때, doc1과 doc2의 문서의 유사도를 구하기 위한 자카드 유사도는 다음과 같다.\n",
    "![자카드 유사도](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/Jaccard%20similarity_%EC%9C%A0%EC%82%AC%EB%8F%84.PNG?raw=True)\n",
    "두 문서 doc1, doc2 사이의 자카드 유사도 J(doc1, doc2)는 두 집합의 교집합 크기를 두 집합의 합집합 크기로 나눈 값으로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
      "['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n"
     ]
    }
   ],
   "source": [
    "# 다음과 같은 두 개의 문서가 있습니다.\n",
    "# 두 문서 모두에서 등장한 단어는 apple과 banana 2개.\n",
    "doc1 = \"apple banana everyone like likey watch card holder\"\n",
    "doc2 = \"apple banana coupon passport love you\"\n",
    "\n",
    "# 토큰화 수행\n",
    "tokenized_doc1 = doc1.split()\n",
    "tokenized_doc2 = doc2.split()\n",
    "\n",
    "# 토큰화 결과 출력\n",
    "print(tokenized_doc1)\n",
    "print(tokenized_doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합집합 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love', 'everyone', 'watch', 'you', 'card', 'passport', 'banana', 'apple', 'likey', 'holder', 'coupon', 'like'}\n"
     ]
    }
   ],
   "source": [
    "union = set(tokenized_doc1).union(set(tokenized_doc2))\n",
    "print(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 교집합 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banana', 'apple'}\n"
     ]
    }
   ],
   "source": [
    "intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))\n",
    "print(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 교집합의 수를 합집합의 수로 나누면 자카드 유사도가 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(len(intersection)/len(union)) # 2를 12로 나눔."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 문서의 총 단어 집합에서 두 문서에서 공통적으로 등장한 단어의 비율"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
