{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계적 언어 모델(Statistical Language Model, SLM)\n",
    "- 조건부 확률\n",
    "1) P(B|A)=P(A,B)/P(A)<br>\n",
    "2) P(A,B,C,D)=P(A)P(B|A)P(C|A,B)P(D|A,B,C)   - 연쇄 법칙<br>\n",
    "3) P(x1,x2,x3...xn)=P(x1)P(x2|x1)P(x3|x1,x2)...P(xn|x1...xn−1)<br>\n",
    "<br>\n",
    "- 문장에 대한 확률\n",
    "1) 문장 'An adorable little boy is spreading smiles'의 확률<br>\n",
    " - P(An adorable little boy is spreading smiles) <br>\n",
    " - P(w1,w2,w3,w4,w5,...wn)=∏P(wn|w1,...,wn−1)<br>\n",
    " - P(An adorable little boy is spreading smiles)= P(An)×P(adorable|An)×P(little|An adorable)×P(boy|An adorable little)×P(is|An adorable little boy) ×P(spreading|An adorable little boy is)×P(smiles|An adorable little boy is spreading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram\n",
    "- 문장 An adorable little boy is spreading smiles이 있을 때, 각 n에 대해서 n-gram을 전부 구해보면<br>\n",
    "1) nigrams : an, adorable, little, boy, is, spreading, smiles<br>\n",
    "2) bigrams : an adorable, adorable little, little boy, boy is, is spreading, spreading smiles<br>\n",
    "3) trigrams : an adorable little, adorable little boy, little boy is, boy is spreading, is spreading smiles<br>\n",
    "4) 4-grams : an adorable little boy, adorable little boy is, little boy is spreading, boy is spreading smiles<br>\n",
    "<br>\n",
    "- N-gram에 나올 단어의 예측은 n-1개의 단어에만 의존<br>\n",
    "예) 'An adorable little boy is spreading' 다음에 나올 단어를 예측하고 싶다고 할 때, n=4라고 한 4-gram을 이용한 언어 모델을 사용, 즉 n-1인 3개의 단어만 고려<br>\n",
    "An adorable little boy is spreading에서 An adorable little은 무시되고 boy is spreading (?)만을 가지고 (?)을 예측한다.<br>\n",
    "만약 갖고있는 코퍼스에서 boy is spreading가 1,000번 등장하고 boy is spreading insults가 500번 등장했으며, boy is spreading smiles가 200번 등장했다면<br>\n",
    "-> boy is spreading 다음에 insults가 등장할 확률은 50%이며, smiles가 등장할 확률은 20%, 따라서 <b>insults가 더 맞다고 판단</b>\n",
    "<br>\n",
    "<br>\n",
    "- N-gram Language Model의 한계<br>\n",
    "1) 희소 문제(Sparsity Problem)<br>\n",
    ":문장에 존재하는 앞에 나온 단어를 모두 보는 것보다 일부 단어만을 보는 것으로 현실적으로 코퍼스에서 카운트 할 수 있는 확률을 높일 수는 있었지만, n-gram 언어 모델도 여전히 n-gram에 대한 희소 문제가 존재<br>\n",
    "2) n을 선택하는 것은 trade-off 문제<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
