{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding\n",
    "- 컴퓨터나 기계는 문자보다 숫자로 처리\n",
    "- 먼저 단어집합을 만들어야 함. 그래서 앞에서 했던 정수인코딩이 필요\n",
    "- 단어 집합의 단어마다 인덱스가 부여되었으면 이를 벡터로 바꿔주는 것이 원핫인코딩임\n",
    "- 단점:<br>\n",
    " (1) 하나의 값만 1을 가지고 나머지는 0의 값을 가져 저장공간측명에서 비효율적<br>\n",
    " (2) 단어의 유사도를 표현하지 못함<br>\n",
    "    예)삿포로 숙소를 검색하면, 삿포로 료칸, 호텔, 게스트하우스 등 유사단어도 찾아야 함<br>\n",
    " (3) 이러한 단점을 해결하고 위해 - 첫째는 카운트 기반의 벡터화 방법인 LSA, HAL 등이 있으며, 둘째는 예측 기반으로 벡터화하는 NNLM, RNNLM, Word2Vec, FastText 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. One Hot Encoding이란?</b><br>\n",
    "- 단어 집합의 크기를 벡터의 차원으로 표현하고 싶은 단어에 인덱스에 1을 부여하고 다른 인덱스에 0을 부여하는 표현방식<br>\n",
    "1) 각 단어에 고유한 인덱스 부여 (정수 인코딩)<br>\n",
    "2) 표현하고 싶은 단어에 인덱스에 1을 부여하고 다른 인덱스에 0을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '자연어', '에서', '배운다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()     #코엔엘파이의 Okt형태소 분석기로 토큰화\n",
    "token = okt.morphs(\"나는 자연어 처리를 자연어에서 배운다\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '에서': 5, '배운다': 6}\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "for voca in token:\n",
    "    #딕셔너리에 없으면 새롭게 딕셔너리에 추가하고 해당 인덱스 길이를 키로 넣어줌\n",
    "    if voca not in word2index.keys():   \n",
    "        word2index[voca] = len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "    #딕서너리의 총 길이만큼 0으로 채워진 리스트 생성\n",
    "    one_hot_vector = [0]*(len(word2index))  \n",
    "    #원핫인코딩할 word의 인덱스 정보를 가지고 옴\n",
    "    index=word2index[word]\n",
    "    #해당 인덱스 위치에 1로 넣어줌\n",
    "    one_hot_vector[index]=1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"자연어\", word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Keras를 이용한 One-Hot-Encoding</b><br>\n",
    "- to_categorical()을 통해 원핫인코딩 적용<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])  # 각 단어에 대한 인코딩 결과 출력.\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 1, 6, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "sub_text=\"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
    "encoded=t.texts_to_sequences([sub_text])[0]\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = to_categorical(encoded)\n",
    "print(one_hot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
