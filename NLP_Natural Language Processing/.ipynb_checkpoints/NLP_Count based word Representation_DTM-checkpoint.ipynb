{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 단어 행렬(Document-Term Matrix, DTM)\n",
    "- BoW 표현 방법을 이용하여 서로 다른 문서의 BoW들을 결합한 표현 방법\n",
    "- 행과 열을 반대로 선택하면 TDM이라고도 함.\n",
    "- 서로 다른 문서들을 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 문서 단어 행렬(DTM)의 표기법\n",
    " - DTM이란 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것\n",
    " - 각 문서에 대한 BoW를 하나의 행렬로 만든 것\n",
    " - BoW표현을 다수의 문서에 대해서 행렬로 표현<br>\n",
    "\n",
    " 예를 들어<br>\n",
    "문서1 : 먹고 싶은 사과<br>\n",
    "문서2 : 먹고 싶은 바나나<br>\n",
    "문서3 : 길고 노란 바나나 바나나<br>\n",
    "문서4 : 저는 과일이 좋아요<br>\n",
    "<br>\n",
    " 문서 단어 행렬로 표현<br>\n",
    " \n",
    " ![푸리에 변환](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/%EB%AC%B8%EC%84%9C%20%EB%8B%A8%EC%96%B4%20%ED%96%89%EB%A0%AC%EB%A1%9C%20%ED%91%9C%ED%98%84.png?raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 문서 단어 행렬(DTM)의 한계<br>\n",
    "\n",
    " 1) 희소표현(Sparse representation)\n",
    " - 원핫벡터는 단어 집합의 크기가 벡터의 차원이 되고 대부분의 값이 0이 된다.\n",
    " - 공간적 낭비와 계산 리소스 증가 : 원핫벡터의 단점\n",
    " - 전체 코퍼스가 방대한 데이터라면 문서 벡터 차원은 수백만 차원이 되며 대부분의 문서 벡터는 0을 가짐\n",
    " - 대부분의 값이 0인 표현을 \"희소 벡터(sparse vector)\" 또는 \"희소 행렬(sparse matrix)\"라고 부름.\n",
    " - 전처리를 통해 단어 집합의 크기를 줄이는 일은 BoW표현을 사용하는 모델에서 중요 (구두점, 빈도수 낮은 단어, 불용어 제거, 어간이나 표제어 추출 등 단어 정규화 등)\n",
    " \n",
    " 2) 단순 빈도 수 기반 접근\n",
    " - 여러 문서에 등장하는 모든 단어에 대해서 빈도 표기를 하는 것은 한계가 있음\n",
    " - 모든 문서에서 동일하게 the가 빈도수가 높다고 해서 유사한 문서라고 판단해서는 안됨.\n",
    " - DRM에 불용어와 중요한 단어에 대해서 가중치를 준다면 유용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['do', 'know', 'love', 'like', 'should', 'want', 'what', 'you', 'your']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록\n",
    "print(vector.vocabulary_) # 각 단어의 인덱스 확인\n",
    "sorted(vector.vocabulary_, key=operator.itemgetter(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 열의 경우에는 0의 인덱스를 가진 do입니다. do는 세번째 문서에만 등장했기 때문에, 세번째 행에서만 1의 값을 가집니다. 두번째 열의 경우에는 1의 인덱스를 가진 know입니다. know는 첫번째 문서에만 등장했기 때문에 첫번째 행에서만 1의 값을 가짐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
