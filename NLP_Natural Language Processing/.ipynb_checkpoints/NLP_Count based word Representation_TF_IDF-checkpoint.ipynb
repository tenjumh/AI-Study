{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "- DTM 내에 있는 각 단어에 대한 중요도를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TF-IDF(Term Frequency - Inverse Document Frequency)\n",
    " - 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정식을 취함)을 사용\n",
    " - DTM 내의 단어들마다 중요도 가중치 부여\n",
    " - DTM을 만들고 TF-IDF 가중치를 부여\n",
    " - <b>모든 문서에 자주 등장하는 단어는 중요도가 낮고, 특정 문서에만 자주 등장하는 단어는 중요도가 높다고 판단.</b><br>\n",
    "    그래서 영어에서 the나 a와 같은 불용어의 경우에는 모든 문서에 자주 등장하기 때문에 중요도 낮아짐\n",
    " - 활용 : 문서의 유사도 확인, 검색 시스템에서 검색 결과의 중요도 결정, 문서 내에서 특정 단어의 중요도\n",
    " - TF와 IDF를 곱한 값을 의미 : 문서를 d, 단어를 t, 문서의 총 개수를 n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.<br>\n",
    "(2) df(t) : 특정 단어 t가 등장한 문서의 수<br>\n",
    "    예를 들어, 문서2(바나나 1회)와 문서3(바나나 10회)에 바나나가 등장하지만, df(t)상에서 바나나의 df는 2임, 문서3에서 바나나가 10회 등장한 것 중요치 않음.<br>\n",
    "(3) idf(d,t) : df(t)에 반비례하는 수<br>\n",
    "    idf(d,t) = log(n/1+df(t))<br>\n",
    "    - df의 역수가 맞으나 log와 분모에 1을 더해주는 것은 n/df(t)를 사용한다면 총 문서의 수 n이 커질수록 IDF 값이 기하급수적으로 커짐. 그래서 log를 사용\n",
    "    - n=1,000,000이면, log의 밑은 10을 사용\n",
    "    \"idf(d,t) = log(n/df(t))\"일 때,\n",
    "    df(t) = 1 -> idf(d,t) = 6\n",
    "    df(t) = 1,000 -> idf(d,t) = 3\n",
    "    df(t) = 1,000,000 -> idf(d,t) = 0\n",
    "    \"idf(d,t) = n/df(t)\"일 때,\n",
    "    df(t) = 1 -> idf(d,t) = 1,000,000\n",
    "    df(t) = 1,000 -> idf(d,t) = 1,000\n",
    "    df(t) = 1,000,000 -> idf(d,t) = 1\n",
    "    - 1을 분모에 더해 주는 이유는 분모가 0이 되는 것을 막기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 이제는 TF와 곱해야할 값인 IDF를 찾아야함, 자연로그 ln(e = 2.718281...)를 사용함\n",
    " ![푸리에 변환](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/%EB%AC%B8%EC%84%9C%20%EB%8B%A8%EC%96%B4%20%ED%96%89%EB%A0%AC%EB%A1%9C%20%ED%91%9C%ED%98%84.png?raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- idf(d,t) = ln(n/1+df(t)) : n : 문서수, df(t) : 특정 단어 t가 등장한 문서의 수\n",
    "  - \"과일이\" = ln(4/(1+1)) = 0.693147\n",
    "  - \"길고\" = ln(4/(1+1)) = 0.693147\n",
    "  - \"노란\" = ln(4/(1+1)) = 0.693147\n",
    "  - \"먹고\" = ln(4/(2+1)) = 0.287682\n",
    "  - \"바나나\" = ln(4/(2+1)) = 0.287682\n",
    "  - \"사과\" = ln(4/(1+1)) = 0.693147\n",
    "  - \"싶은\" = ln(4/(2+1)) = 0.287682\n",
    "  - \"저는\" = ln(4/(1+1)) = 0.693147\n",
    "  - \"좋아요\" = ln(4/(1+1)) = 0.693147<br>\n",
    "  \n",
    "문서의 총 수는 4이기 때문에 ln 안에서 분자는 늘 4으로 동일합니다. 분모의 경우에는 각 단어가 등장한 문서의 수(DF)를 의미하는데, 예를 들어서 '먹고'의 경우에는 총 2개의 문서(문서1, 문서2)에 등장했기 때문에 2라는 값을 가집니다. 각 단어에 대해서 IDF의 값을 비교해보면 문서 1개에만 등장한 단어와 문서2개에만 등장한 단어는 값의 차이를 보입니다. IDF는 여러 문서에서 등장한 단어의 가중치를 낮추는 역할을 하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![푸리에 변환](https://github.com/tenjumh/GraduateSchool/blob/master/Study/NLP_Natural%20Language%20Processing/image/%EB%AC%B8%EC%84%9C%20%EB%8B%A8%EC%96%B4%20%ED%96%89%EB%A0%AC%EB%A1%9C%20%ED%91%9C%ED%98%84_TF-IDF.png?raw=True)\n",
    "\n",
    "앞서 사용한 DTM에서 단어 별로 위의 IDF값을 그대로 곱해주면 TF-IDF가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',\n",
    "]\n",
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
