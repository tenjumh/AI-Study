{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 (Ensemble)\n",
    "- 여러 개의 모델을 학습시켜 그 모델들의 예측 결과들을 이용해 하나의 모델보다 더 나은 값을 예측하는 방법\n",
    "- 여러 개의 약 분류기를 결합하여 강 분류기를 만드는 것\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "###   1. 배깅 (Bagging; bootstrap aggregation)\n",
    "- 샘플을 여러 개 뽑아서 각 모델을 학습시켜 결과물을 집계하는 방식\n",
    "    1. 부트스트랩 수행 (training data에서 복원 랜덤 샘플링하여 여러 training data을 만든다)\n",
    "        - sample 개수는 \"하이퍼파라미터\"\n",
    "    2. 각 sample별로 Decision Tree 수행\n",
    "        - Decision Tree : 출력(target)에 대해 입력 1, 입력 2, 입력 3,...과 각각 쪼개서 Gain을 가지고 제일 좋은 것을 기준으로 tree를 만듬.\n",
    "    3. Unknown data를 모든 decision tree에 넣어보고 결과를 투표\n",
    "    4. 다수결에 의해 투표 값으로 예측\n",
    "    \n",
    " <br>\n",
    " <br>\n",
    " ### 2. 랜덤 포레스트 (Random Forests)\n",
    " - 모든 것이 배깅과 동일하나, 2. 각 sample별로 Decision Tree 수행 시, 입력 10개 중 일부인 X개만 random하게 골라서 Gain을 가지고 제일 좋은 것을 기준으로 Tree를 만듬\n",
    "     - X개를 random하게 고를 때 개수는 \"하이퍼파라미터\"\n",
    " - 요소 하나하나의 정확도는 떨어지나 bagging으로 합치기에 Cover됨\n",
    " - 또한 가지는 깊지 않고 입력 개수가 적어져 시간이 절약\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
