{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신용카드 번호 인식하기\n",
    "- 목표 : OpenCV를 활용한 TEXT 영역 검출\n",
    "- 유니크한 신용카드 숫자 모듈을 통한 인식\n",
    "- 참고 싸이트 : https://blog.naver.com/tommybee/221837611962\n",
    "- 여권 인식 : https://www.pyimagesearch.com/2015/11/30/detecting-machine-readable-zones-in-passport-images/\n",
    "- 여권 인식 : https://www.pyimagesearch.com/2015/11/30/detecting-machine-readable-zones-in-passport-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade imutils\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# construct the argument parser and parse the arguments\n",
    "# argparse란? https://blog.naver.com/qbxlvnf11/221801181428\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to input image\")\n",
    "ap.add_argument(\"-r\", \"--reference\", required=True, help=\"path to reference OCR-A image\")\n",
    "args = vars(ap.parse_args())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--image : OCR'd가 될 이미지의 경로.\n",
    "--reference : 참조 OCR-A 영상의 경로.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary that maps the first digit of a credit cart\n",
    "# number to the credit card type\n",
    "FIRST_NUMBER = {\n",
    "    \"3\": \"American Express\",\n",
    "    \"4\": \"Visa\",\n",
    "    \"5\": \"MasterCard\",\n",
    "    \"6\": \"Discover Card\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference OCR-A image from disk, convert it to grayscale.\n",
    "# and threshold it, such that the digits appear as *white* on a *black* background\n",
    "# and invert it, such that the digits appear as *white* on a *black*\n",
    "# ref = cv2.imread(args[\"reference\"])\n",
    "#ref = cv2.imread('./reference/OCR-A_char_digits.png', 0)\n",
    "ref = cv2.imread('./reference/OCR-A_char_digits.jpg', 0)\n",
    "#ref = cv2.cvtColor(ref, cv2.COLOR_BGR2GRAY)\n",
    "#ref = cv2.threshold(ref, 10, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow('ref', ref)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윤곽선 검출\n",
    "refCnts = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "refCnts = imutils.grab_contours(refCnts)\n",
    "refCnts = contours.sort_contours(refCnts, method='left-to-right')[0]\n",
    "digits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the OCR-A reference contours\n",
    "# 각 검출 객체마다 순환하면서 좌표정보를 취득하고 ROI를 57x88로 고정\n",
    "# 해당 roi를 digits dictionary에 저장\n",
    "for (i, c) in enumerate(refCnts):\n",
    "    # compute the bounding box for the digit, extract it, and resize\n",
    "    # it to a fixed size\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    roi = ref[y:y + h, x:x + w]\n",
    "    roi = cv2.resize(roi, (57, 88))\n",
    "    \n",
    "    # update the digits dictionary, mapping the digit name to the ROI\n",
    "    digits[i] = roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image 폴더 내의 신용카드 이미지 데이터에서 신용카드 번호 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 구조화 커널을 초기화\n",
    "# initalize a rectangular (wider than it is tall) and square\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3))  # 직사각형 커널\n",
    "sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))   # 정사각형 커널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커널로 convolution하면서 blur, sharpen(갈림), edge detection 작업 진행\n",
    "# load input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread('./image/creditcard_visa.jpg')\n",
    "image = imutils.resize(image, width=300)\n",
    "# image2 = cv2.resize(image, (300, 192))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('image_org', image)\n",
    "cv2.imshow('image_gray', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a tophat morphological operator to find light\n",
    "# regions against a dark background (i.e the credit card numbers)\n",
    "tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel)\n",
    "cv2.imshow('tophat', tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tophat 이미지에서 x-방향의 그라디언트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Scharr gradient of the tophat image, then scale\n",
    "# the rest back into the range [0, 255]\n",
    "# 소벨을 통해 엣지 검출 (하기 이미지 참조)\n",
    "gradX = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "gradX = np.absolute(gradX)\n",
    "gradY = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n",
    "gradY = np.absolute(gradY)\n",
    "cv2.imshow('image_org', image)\n",
    "cv2.imshow('gradX', gradX)\n",
    "cv2.imshow('gradY', gradY)\n",
    "\n",
    "(minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "gradX = (255 * ((gradX - minVal) / (maxVal - minVal)))\n",
    "gradX = gradX.astype('uint8')\n",
    "cv2.imshow('gradX_x', gradX)\n",
    "\n",
    "(minVal, maxVal) = (np.min(gradY), np.max(gradY))\n",
    "gradY = (255 * ((gradY - minVal) / (maxVal - minVal)))\n",
    "gradY = gradY.astype('uint8')\n",
    "cv2.imshow('gradY_y', gradY)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel\n",
    "![sobel](https://github.com/tenjumh/GraduateSchool/blob/master/Computer%20Vision/Image%20Edge_operators/image/Sobel.PNG?raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a closing operation using the rectangular kernel to help\n",
    "# close gaps in between credit card number digits, then apply\n",
    "# Otsu's thresholding method to binarize the image\n",
    "gradX_ = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
    "thresh = cv2.threshold(gradX_, 0 , 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# apply a second closing operation to the binary image, again\n",
    "# to help close gaps between credit card number regions\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 10), dpi=150)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gradX, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(thresh, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
